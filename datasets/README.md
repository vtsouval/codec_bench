# ğŸ“š ARCH Benchmark Datasets

## âœ… Integrated Datasets

### ğŸµ Music

- [x] FMA-small â€” Music genre classification
- [x] GTZAN â€” Music genre classification
- [x] Medley-solos-DB â€” Instrument recognition

### ğŸ—£ï¸ Speech

- [x] AudioMNIST â€” Digit classification
- [x] SLURP â€” Spoken language understanding (intent classification)
- [x] TIMIT â€” Dialect region classification
- [x] CREMA-D â€” Emotional speech (English)
- [x] EMOVO â€” Emotional speech (Italian)
- [x] RAVDESS â€” Emotional speech and song classification

### ğŸ”‰ Paralinguistic / Environmental

- [x] ESC-50 â€” Environmental sound classification
- [x] US8K â€” Urban sound classification
- [x] FSD50K â€” Human-labeled sound events
- [x] ARCA23K-FSD â€” Sound event classification (subset of FSD50K)
- [x] VIVAE â€” Affective non-speech vocalization classification

---

### ğŸ“‹ Upcoming Datasets (Planned Integration)

#### ğŸµ Music
- [ ] MTG-Jamendo â€” Multi-label music tagging (genre, mood, instrumentation)

#### ğŸ—£ï¸ Speech
- [ ] IEMOCAP â€” Multimodal emotion recognition from speech and video

---

## ğŸ—‚ï¸ Datasets Preparation

To preprocess a dataset, run the corresponding `*_gen.py` script located in the `scripts/` directory.

```bash
# Example: Preprocess the AudioMNIST dataset
python scripts/audiomnist_gen.py
```
