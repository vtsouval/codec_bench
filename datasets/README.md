# ğŸ“š ARCH Benchmark (extended!)

## âœ… Integrated Datasets

### ğŸµ Music

- [x] FMA-small â€” Music genre classification
- [x] GTZAN â€” Music genre classification
- [x] Medley-solos-DB â€” Instrument recognition
- [ ] MTG-Jamendo (Genre) â€” Single-label genre classification
- [ ] MTG-Jamendo (Mood) â€” Single-label mood classification

### ğŸ—£ï¸ Speech

- [x] AudioMNIST â€” Digit classification
- [x] SLURP â€” Spoken language understanding (intent classification)
- [x] TIMIT â€” Dialect region classification
- [ ] VCTK â€” Speaker identification
- [x] CREMA-D â€” Emotional speech (English)
- [x] EMOVO â€” Emotional speech (Italian)
- [x] RAVDESS â€” Emotional speech and song classification

### ğŸ”‰ Paralinguistic / Environmental

- [x] ESC-50 â€” Environmental sound classification
- [x] US8K â€” Urban sound classification
- [x] ARCA23K-FSD â€” Sound event classification (subset of FSD50K)
- [x] VIVAE â€” Affective non-speech vocalization classification
- [x] FluSense â€” Illness-related sound detection (e.g., cough, sneeze)

---

## ğŸ—‚ï¸ Datasets Preparation

To preprocess a dataset, run the corresponding `*_gen.py` script located in the `scripts/` directory.

```bash
# Example: Preprocess the AudioMNIST dataset
python scripts/audiomnist_gen.py
```
